{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyEXaQ8IAN+FZ9BSe2T4qD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sensationalspace/colab/blob/main/sensational_tot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain, LangSmith & LLM Guided Tree-of-Thought\n",
        "The Three-of-Thought (ToT) technique takes inspiration from the way human minds solve complex reasoning tasks by trial and error. In this approach, the mind explores the solution space through a thought process resembling a tree, enabling backtracking when needed. This article considers the ToT research paper and how LangChain implemented the ToT approach."
      ],
      "metadata": {
        "id": "aZEE8kEFPZbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cobusgreyling.medium.com/langchain-hub-76fdcd0ba9ae"
      ],
      "metadata": {
        "id": "uz2Usj1iPxtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://miro.medium.com/v2/resize:fit:2000/format:webp/1*u9V_NiPBMeWwGmVNJw4lRw.png"
      ],
      "metadata": {
        "id": "bsEgppUnPyz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \\\n",
        "    langchain \\\n",
        "    langchain_experimental \\\n",
        "    langsmith \\\n",
        "    datasets==2.14.3 \\\n",
        "    openai==0.27.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shHiKtG9Qz3Y",
        "outputId": "1f4a7e83-d3b3-4875-dff4-2a93a27d08a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.1/519.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgtMqtSgPRAW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from uuid import uuid4\n",
        "\n",
        "unique_id = uuid4().hex[0:8]\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Agent Tot\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "os.environ['OPENAI_API_KEY'] = str(\"xxxxxxxxxxxxxxxxxxxxxxxx\")\n",
        "\n",
        "#######\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=1, max_tokens=512, model=\"text-davinci-003\")\n",
        "\n",
        "#######\n",
        "\n",
        "sudoku_puzzle =   \"3,*,*,2|1,*,3,*|*,1,*,3|4,*,*,1\"\n",
        "sudoku_solution = \"3,4,1,2|1,2,3,4|2,1,4,3|4,3,2,1\"\n",
        "problem_description = f\"\"\"\n",
        "{sudoku_puzzle}\n",
        "\n",
        "- This is a 4x4 Sudoku puzzle.\n",
        "- The * represents a cell to be filled.\n",
        "- The | character separates rows.\n",
        "- At each step, replace one or more * with digits 1-4.\n",
        "- There must be no duplicate digits in any row, column or 2x2 subgrid.\n",
        "- Keep the known digits from previous valid thoughts in place.\n",
        "- Each thought can be a partial or the final solution.\n",
        "\"\"\".strip()\n",
        "print(problem_description)\n",
        "\n",
        "#######\n",
        "# The following code implement a simple rule based checker for\n",
        "# a specific 4x4 sudoku puzzle.\n",
        "#######\n",
        "\n",
        "from typing import Tuple\n",
        "from langchain_experimental.tot.checker import ToTChecker\n",
        "from langchain_experimental.tot.thought import ThoughtValidity\n",
        "import re\n",
        "\n",
        "class MyChecker(ToTChecker):\n",
        "    def evaluate(self, problem_description: str, thoughts: Tuple[str, ...] = ()) -> ThoughtValidity:\n",
        "        last_thought = thoughts[-1]\n",
        "        clean_solution = last_thought.replace(\" \", \"\").replace('\"', \"\")\n",
        "        regex_solution = clean_solution.replace(\"*\", \".\").replace(\"|\", \"\\\\|\")\n",
        "        if sudoku_solution in clean_solution:\n",
        "            return ThoughtValidity.VALID_FINAL\n",
        "        elif re.search(regex_solution, sudoku_solution):\n",
        "            return ThoughtValidity.VALID_INTERMEDIATE\n",
        "        else:\n",
        "            return ThoughtValidity.INVALID\n",
        "\n",
        "#######\n",
        "# Testing the MyChecker class above:\n",
        "#######\n",
        "\n",
        "checker = MyChecker()\n",
        "assert checker.evaluate(\"\", (\"3,*,*,2|1,*,3,*|*,1,*,3|4,*,*,1\",)) == ThoughtValidity.VALID_INTERMEDIATE\n",
        "assert checker.evaluate(\"\", (\"3,4,1,2|1,2,3,4|2,1,4,3|4,3,2,1\",)) == ThoughtValidity.VALID_FINAL\n",
        "assert checker.evaluate(\"\", (\"3,4,1,2|1,2,3,4|2,1,4,3|4,3,*,1\",)) == ThoughtValidity.VALID_INTERMEDIATE\n",
        "assert checker.evaluate(\"\", (\"3,4,1,2|1,2,3,4|2,1,4,3|4,*,3,1\",)) == ThoughtValidity.INVALID\n",
        "\n",
        "#######\n",
        "# Initialize and run the ToT chain,\n",
        "# with maximum number of interactions k set to 30 and\n",
        "# the maximum number child thoughts c set to 8.\n",
        "#######\n",
        "\n",
        "from langchain_experimental.tot.base import ToTChain\n",
        "\n",
        "tot_chain = ToTChain(llm=llm, checker=MyChecker(), k=30, c=5, verbose=True, verbose_llm=False)\n",
        "tot_chain.run(problem_description=problem_description)\n",
        "\n",
        "#######"
      ]
    }
  ]
}