{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sensationalspace/colab/blob/main/openai_assistants_files_api_based_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Assistants and Files API based RAG Application\n",
        "\n",
        "**Assistants API** allows developers to build AI assistants that can handle the stateful operations required for LLM based applications, including persistent threads and messages, files, and automatic RAG.\n",
        "\n",
        "An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools:\n",
        "\n",
        "- Code Interpreter\n",
        "- Retrieval\n",
        "- Function calling\n",
        "\n",
        "Notice that, when we give `Assistants` access to OpenAI-hosted tools listed above, the usage of the tools comes at an additional fee.\n",
        "\n",
        "**RAG** (Retrieval Augmented Generation) is a technique used in natural language processing that employes the capabilities of retrieval-based models and generative models to improve the quality and relevance of generated text.\n",
        "\n",
        "Document based QA bot is a classic use case of RAG. The mainstream LLM frameworks for example `LangChain` and `LlamaIndex` support building such RAG application.\n",
        "\n",
        "In this tutorial, I will show you how to develop a RAG application with OpenAI `Assistants` and `Files` API. The code may be cleaner, the solution may be more elegant, and it may cost a bit more, considering the extra charge for using OpenAI hosted tool - **`Retrieval`**.\n",
        "\n",
        "With this solution, you don't have to deal with the following tedious operations:\n",
        "\n",
        "- Split text with proper strategy\n",
        "- Vectorize text chunks\n",
        "- Persist vector data set\n",
        "- Similarity search\n"
      ],
      "metadata": {
        "id": "Dej4rmcv1qCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the environment\n",
        "\n",
        "In order to run the example code below, make sure you have a valid OpenAI API key with access to the model `gpt-4-1106-preview`.\n",
        "\n",
        "You also should have the `.env` file ready in current directory with the content in the pattern below:\n",
        "\n",
        "```shell\n",
        "OPENAI_API_KEY=sk-xxxxxx\n",
        "```\n",
        "\n",
        "Now let's install the necessary Python packages."
      ],
      "metadata": {
        "id": "ipQHI0Fe7OP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GkF_TXMN2AML",
        "outputId": "abe82acc-2ba8-4a88-d97c-bbe619ea0a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai python-dotenv -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding Time\n",
        "\n",
        "We can start coding. In this example, we will use the following PDF file as the knowledge base:\n",
        "\n",
        "[2023 Venture Capital Report](https://www.wilmerhale.com/-/media/files/shared_content/editorial/publications/documents/2023-wilmerhale-vc-report.pdf)\n",
        "\n",
        "This is a Venture Capital report of 2023 issued by WilmerHale."
      ],
      "metadata": {
        "id": "O2f7XFsu8BIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load"
      ],
      "metadata": {
        "id": "qUpdc89s8lmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "ywRTtMmR2UKV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "5Yp_M4W7aL98"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "GeW4OJ6Y2rR7",
        "outputId": "d00d16ed-4f86-4474-abcd-c957a50397ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'OPENAI_API_KEY'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e91d203dc33e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'OPENAI_API_KEY'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# You don't have to explicitly fetch the API key from environmental variables and assign it.\n",
        "# OpenAI class will load it from env var OPENAI_API_KEY automatically.\n",
        "\n",
        "openai_client = openai.OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "LPz0oCZkEcwb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Retrieve existing files\n",
        "\n",
        "The files uploaded via `OpenAI Files API` are persisted. They can be surely reused by referring to their ids.\n",
        "\n",
        "In this step, we will retrieve the files already uploaded and see if the PDF file `2023-WilmerHale-VC-Report.pdf` exists.\n",
        "\n",
        "If so, let's delete and upload again."
      ],
      "metadata": {
        "id": "lNi_L5_V9mZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the file list\n",
        "\n",
        "uploaded_files = openai_client.files.list()"
      ],
      "metadata": {
        "id": "2LTwlGShzYJd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_files.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0YAls8qzkoH",
        "outputId": "be01d797-85c2-4a3e-86bc-b91b1c91a1c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[FileObject(id='file-OBCZJllc4DvZQw1COreqhT0M', bytes=1365871, created_at=1713637948, filename='Campbell Soup 10-k.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-ukOWB1ivgQxx8D66UEXb99LL', bytes=1365871, created_at=1711210141, filename='Campbell_Soup_10k_2023.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-cOs8oTdD8tH3JMVS0Y5IwyfP', bytes=2032131, created_at=1708867333, filename='Smucker_10k_2023.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-CjM8XqjUfrsQG4MAU88YVSMQ', bytes=1076676, created_at=1708867333, filename='Pepsi_10k_2022.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-9WXU1TptyAtUGiPFbOQzo8fC', bytes=2299116, created_at=1708867332, filename='Nestle_10k_2022.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-tEcMqzvptAZYUUYLGEBXkI6b', bytes=949770, created_at=1708867331, filename='Kellogs_10k_2023.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-43Fz0bN2WIlmX34ruvSumW8B', bytes=789786, created_at=1708867331, filename='Lamb_Weston_10k_2023.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-gsWLzuTZD2BWKd8b5UUahRd6', bytes=1731620, created_at=1708867330, filename='General_Mills_10k_2023.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-PYUeFlFKwTmXuVxRQ4phWWFH', bytes=5452041, created_at=1708867329, filename='Eastman_10k_2022.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-iq4zuGzSjZJ4zcII655Xsb72', bytes=690617, created_at=1708867328, filename='Conagra_10k_2023.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-BhF3WlnHZD0oIdUBIJgxMwlE', bytes=1365871, created_at=1708867327, filename='Campbell_Soup_10k_2023.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-3Nb1VFv0G6EaZchEJodYSjXx', bytes=872846, created_at=1708867327, filename='B&G_10k_2018.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-xlqbR5wWOtHsSl1hKUo2fnlg', bytes=7220, created_at=1705654491, filename='chicstays_trips.json', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-KLa8pSjnZuL8NJ7mNcViXrLy', bytes=7220, created_at=1705624019, filename='chicstays_trips.json', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-Ls6H7SElJRWKszY5Di19TyBS', bytes=3152, created_at=1705080292, filename='chicstays_trips.json', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-tdx2fF4Xd9a5x9ZQt4VVZHXi', bytes=3156, created_at=1705080031, filename='chicstays_trips.json', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-dbqE14ooHt2Dm110WsDwVodd', bytes=3156, created_at=1705079330, filename='chicstays_trips.json', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-vFSRXq3KHHMfOw6FKq5t159Q', bytes=1317, created_at=1704742619, filename='The-ultimate-St-Barths--itinerary.txt', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-pe3PcdW7QgcGAbTiYj5lF7Rr', bytes=552, created_at=1704742619, filename='epic-PCH-california-roadtrip.txt', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-o2ztpcew4nimB2DjWScQOARW', bytes=1317, created_at=1704738415, filename='itinerary.txt', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-95U7GUE73Il1BthCZgFP6jYk', bytes=1317, created_at=1704738398, filename='itinerary.txt', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-Z9j1ofX7maYpPwDBpxa5jNyN', bytes=1315, created_at=1704738249, filename='itinerary.txt', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-d5G54N0YSacvpgYQ6cQFcAg1', bytes=None, created_at=1703700605, filename='19068871-1812-429b-a1d2-0076028306f5', object='file', purpose='assistants_output', status='processed', status_details=None),\n",
              " FileObject(id='file-ybu9I9F36RteW95cK2KUwyIW', bytes=949770, created_at=1703020432, filename='Kellogs 10-k.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-8iezXV1VAeiCUfdnxctQjw82', bytes=949770, created_at=1703020384, filename='Kellogs 10-k-1.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-N3ohGBvRGOd6td0g42331yrQ', bytes=67183, created_at=1703019886, filename='Prompts.docx', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-Yllv6w9f8fsic4D4AMhPFa2L', bytes=41882, created_at=1701683906, filename='Stephen-Adebola-long.docx', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-6QduHi1543MtHyxihtn71103', bytes=1440303, created_at=1700090064, filename='lyft_2021.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
              " FileObject(id='file-UKuC8dViK0QYosbRgHmQJcIa', bytes=38764, created_at=1699316187, filename='Stephen-Adebola-2023-v03.docx', object='file', purpose='assistants', status='processed', status_details=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the file by name\n",
        "\n",
        "filename_to_find = '2023-WilmerHale-VC-Report.pdf'\n",
        "the_file_id = None\n",
        "\n",
        "file_objects = list(filter(lambda x: x.filename == filename_to_find, uploaded_files.data))\n",
        "\n",
        "if len(file_objects) > 0:\n",
        "  the_file_id = file_objects[0].id"
      ],
      "metadata": {
        "id": "aROVPPAl-a-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_file_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m0NMZ59sIC-N",
        "outputId": "8287e04c-d9c3-4b5a-837f-64c5ae444d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-1zy5eXDx5nDotjUp4tybtNGl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete if it already exists.\n",
        "\n",
        "Notice that, this is for demonstration purpose."
      ],
      "metadata": {
        "id": "IJVmHdvP_wB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if the_file_id:\n",
        "  delete_status = openai_client.files.delete(the_file_id)\n",
        "  delete_status"
      ],
      "metadata": {
        "id": "DVouWaqgzr4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Upload the PDF file\n",
        "\n",
        "This PDF file will be the knowledge base of the RAG application."
      ],
      "metadata": {
        "id": "eBpTSwLQ_2we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = openai_client.files.create(\n",
        "  file=open(\"2023-WilmerHale-VC-Report.pdf\", \"rb\"),\n",
        "  purpose='assistants'\n",
        ")"
      ],
      "metadata": {
        "id": "MIbK3o4XFH1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BEJW7lxFXVX",
        "outputId": "58cd48e1-3320-49d6-d4c9-64c076ef328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-p1e3aGURKtzkR83g91YUTBhn', bytes=1310948, created_at=1700171663, filename='2023-WilmerHale-VC-Report.pdf', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Retrieve the file by id\n",
        "\n",
        "This is to make sure the file is successfully uploaded."
      ],
      "metadata": {
        "id": "agL44d-1__wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_file = openai_client.files.retrieve(file.id)\n",
        "retrieved_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vg3-7t3cb2_",
        "outputId": "c305d4f6-3174-44d5-a97e-8cefe203d7b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-p1e3aGURKtzkR83g91YUTBhn', bytes=1310948, created_at=1700171663, filename='2023-WilmerHale-VC-Report.pdf', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Create an Assistant\n",
        "\n",
        "This Assistant will use the tool `Retrieval` and get associated with the PDF file uploaded by its id."
      ],
      "metadata": {
        "id": "ju7oOHNfAI2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = openai_client.beta.assistants.create(\n",
        "  instructions=\"Use the file provided as your knowledge base to best respond to customer queries.\",\n",
        "  model=\"gpt-4-1106-preview\",\n",
        "  tools=[\n",
        "      { \"type\": \"retrieval\" }\n",
        "    ],\n",
        "  file_ids=[retrieved_file.id]\n",
        ")"
      ],
      "metadata": {
        "id": "iwD1noKvFds9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Retrieve the created Assistant\n",
        "\n",
        "It's retrieved by the assistant id.\n",
        "\n",
        "We must make sure in the response, we can see expected tool and file are associated with it."
      ],
      "metadata": {
        "id": "uAZ0Y-egATbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_assistant = openai_client.beta.assistants.retrieve(assistant.id)\n",
        "my_assistant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU7XgHKfcJmG",
        "outputId": "5a8bfafb-ed28-4ce9-b7ee-cd7cf718ca54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Assistant(id='asst_YYN7UKBkyuFs5UghtNfzxO3z', created_at=1700171729, description=None, file_ids=['file-p1e3aGURKtzkR83g91YUTBhn'], instructions='Use the file provided as your knowledge base to best respond to customer queries.', metadata={}, model='gpt-4-1106-preview', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. (Optional) Update the Assistant\n",
        "\n",
        "I noticed once that the created assistant didn't have the tool and file associated.\n",
        "\n",
        "When it happens to you, use the `update` function to associate them again."
      ],
      "metadata": {
        "id": "Gyba9nuNAgqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_assistant = openai_client.beta.assistants.update(\n",
        "  assistant.id,\n",
        "  tools=[{\"type\": \"retrieval\"}],\n",
        "  file_ids=[retrieved_file.id],\n",
        ")\n",
        "\n",
        "updated_assistant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am6RzSLfeEs3",
        "outputId": "a206f689-2af1-4a3d-e6ab-b02a62bbd271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Assistant(id='asst_YYN7UKBkyuFs5UghtNfzxO3z', created_at=1700171729, description=None, file_ids=['file-p1e3aGURKtzkR83g91YUTBhn'], instructions='Use the file provided as your knowledge base to best respond to customer queries.', metadata={}, model='gpt-4-1106-preview', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Create a Thread"
      ],
      "metadata": {
        "id": "e1pi3ta8AvX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread = openai_client.beta.threads.create()\n",
        "\n",
        "thread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H1cR3XdF0R1",
        "outputId": "6adcb900-cad0-437b-ee24-15a44ac39504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Thread(id='thread_PIN1poM9aRX4sYjnnohlvZNa', created_at=1700171825, metadata={}, object='thread')"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Create a Message\n",
        "\n",
        "We are going to use a message object to request the Assistant to extract the content architecture out of the PDF file."
      ],
      "metadata": {
        "id": "PiCMxyJNAyEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread_message = openai_client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"Please show me the content architecture of this report\",\n",
        ")\n",
        "thread_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD4YL8apMoUV",
        "outputId": "7c31e5ba-499d-4e3b-a2dd-e05d823987fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreadMessage(id='msg_r00GeAZ3q4zaQYxaYlGsjMmd', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Please show me the content architecture of this report'), type='text')], created_at=1700171844, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_PIN1poM9aRX4sYjnnohlvZNa')"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Create a Run\n",
        "\n",
        "A `Run` triggers the interaction to the LLM."
      ],
      "metadata": {
        "id": "x8jMsm-DBG8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = openai_client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=updated_assistant.id\n",
        ")"
      ],
      "metadata": {
        "id": "Yp1Fr_FEL65n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Retrieve the Run\n",
        "\n",
        "The `Run` is done in async mode, so we need to query the status of the Run by id."
      ],
      "metadata": {
        "id": "o7HYAnqABRay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_run = openai_client.beta.threads.runs.retrieve(\n",
        "  thread_id=thread.id,\n",
        "  run_id=run.id\n",
        ")"
      ],
      "metadata": {
        "id": "rCv4p11TNJUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nILYSfeINRnw",
        "outputId": "6ca7eb08-dcdd-4d09-c52f-c5556b800fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(id='run_uGwTGAemL5rqFwWlHc02Wxwl', assistant_id='asst_YYN7UKBkyuFs5UghtNfzxO3z', cancelled_at=None, completed_at=1700171869, created_at=1700171854, expires_at=None, failed_at=None, file_ids=['file-p1e3aGURKtzkR83g91YUTBhn'], instructions='Use the file provided as your knowledge base to best respond to customer queries.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1700171854, status='completed', thread_id='thread_PIN1poM9aRX4sYjnnohlvZNa', tools=[ToolAssistantToolsRetrieval(type='retrieval')])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11. Retrieve the message list of the Thread\n",
        "\n",
        "Until the Run is completed, retrieve the message list and fetch the latest message of the list which is the response of the LLM."
      ],
      "metadata": {
        "id": "fCcSFIXoBc6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread_messages = openai_client.beta.threads.messages.list(thread.id)\n",
        "thread_messages.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAbqv9S7Ne3n",
        "outputId": "37a14842-5c11-47db-e177-d5ef1ae63a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ThreadMessage(id='msg_UYQX4LrKPLpVNjhjBQRUGO07', assistant_id='asst_YYN7UKBkyuFs5UghtNfzxO3z', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=817, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-p1e3aGURKtzkR83g91YUTBhn', quote='2023 Venture Capital Report – What’s Inside\\n\\n\\n2  US Market Review and Outlook\\n\\n\\n6  Regional Market Review and Outlook\\n\\n\\n10 Selected WilmerHale Venture Capital Financings\\n\\n\\n12 New Law Requires Federal Reporting of Private Company Ownership\\nMany Startups and Life Sciences Companies Will be Subject to Beneficial Ownership\\nReporting\\n\\n\\n13 Show Me the Money\\nWhat Employers Need to Know About New Salary Disclosure Laws\\n\\n\\n14 Navigating the Quiet Period Shoals\\nSafe Harbors Aid Compliance With Quiet Period Requirements\\n\\n\\n16 State Taxation of Qualified Small Business Stock\\nFederal Tax Exclusion Not Always Replicated at State Level\\n\\n\\n17 Trends in VC-Backed Company M&A Deal Terms\\n\\n\\n18 Trends in Convertible Note and SAFE Terms\\n\\n\\n19 Trends in Venture Capital Financing Terms'), start_index=807, text='【7†source】', type='file_citation')], value='The content architecture of the 2023 Venture Capital Report includes the following sections:\\n\\n1. US Market Review and Outlook\\n2. Regional Market Review and Outlook\\n3. Selected WilmerHale Venture Capital Financings\\n4. New Law Requires Federal Reporting of Private Company Ownership (Many Startups and Life Sciences Companies Will be Subject to Beneficial Ownership Reporting)\\n5. Show Me the Money (What Employers Need to Know About New Salary Disclosure Laws)\\n6. Navigating the Quiet Period Shoals (Safe Harbors Aid Compliance With Quiet Period Requirements)\\n7. State Taxation of Qualified Small Business Stock (Federal Tax Exclusion Not Always Replicated at State Level)\\n8. Trends in VC-Backed Company M&A Deal Terms\\n9. Trends in Convertible Note and SAFE Terms\\n10. Trends in Venture Capital Financing Terms【7†source】.'), type='text')], created_at=1700171861, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_uGwTGAemL5rqFwWlHc02Wxwl', thread_id='thread_PIN1poM9aRX4sYjnnohlvZNa'),\n",
              " ThreadMessage(id='msg_r00GeAZ3q4zaQYxaYlGsjMmd', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Please show me the content architecture of this report'), type='text')], created_at=1700171844, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_PIN1poM9aRX4sYjnnohlvZNa')]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(thread_messages.data[0].content[0].text.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxVMc18Tem5u",
        "outputId": "51201c38-9374-4157-c38d-7ae718b87a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The content architecture of the 2023 Venture Capital Report includes the following sections:\n",
            "\n",
            "1. US Market Review and Outlook\n",
            "2. Regional Market Review and Outlook\n",
            "3. Selected WilmerHale Venture Capital Financings\n",
            "4. New Law Requires Federal Reporting of Private Company Ownership (Many Startups and Life Sciences Companies Will be Subject to Beneficial Ownership Reporting)\n",
            "5. Show Me the Money (What Employers Need to Know About New Salary Disclosure Laws)\n",
            "6. Navigating the Quiet Period Shoals (Safe Harbors Aid Compliance With Quiet Period Requirements)\n",
            "7. State Taxation of Qualified Small Business Stock (Federal Tax Exclusion Not Always Replicated at State Level)\n",
            "8. Trends in VC-Backed Company M&A Deal Terms\n",
            "9. Trends in Convertible Note and SAFE Terms\n",
            "10. Trends in Venture Capital Financing Terms【7†source】.\n"
          ]
        }
      ]
    }
  ]
}